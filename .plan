Before we do this, we need to sort out a modular, custom material system:

How it Would Work:
1.  BaseMaterial: This would be an abstract class containing the common properties (albedoTexture, doubleSided, etc.) and the specialization object.
2.  Concrete Material Classes: We would then provide several concrete implementations for users.
        //--- For the User ---
    // The simplest possible material
    export class BasicMaterial extends BaseMaterial {
      constructor() {
        super();
        // No specialization needed
      }
    }
    // A material that enables our custom toon shading
    export class ToonMaterial extends BaseMaterial {
      gradientMapTexture: Texture;
      
      constructor(gradientMap: Texture) {
        super();
        this.gradientMapTexture = gradientMap;
        this.specialization.useGradientMap = true; // Automatically enable the shader feature
      }
    }
    // A future material for something like animated foliage
    export class AnimatedMaterial extends BaseMaterial {
      constructor() {
        super();
        this.specialization.useVertexAnimation = true;
      }
    }
    
Advantages of this approach:
*   Excellent DX: This is very clean for the consumer. They just instantiate the material type they need (new BasicMaterial()) without having to worry about the underlying flags or shader permutations.
*   Type-Safe and Discoverable: The properties on each material class are explicit. ToonMaterial has a gradientMapTexture; BasicMaterial does not. This is great for auto-completion and preventing errors.
*   Scalable: It's incredibly easy to add new material types in the future without breaking existing code.
Summary of the Brainstorm
By combining these two ideas, we get a powerful, flexible, and user-friendly system:
1.  Multiple Material classes (BasicMaterial, ToonMaterial) provide a clean, high-level interface for the user.
2.  Each material class sets specialization flags that describe its features.
3.  The MaterialManager uses these flags to cache and switch between different, highly optimized GPURenderPipeline permutations derived from a single, modular uber-shader.
This is a robust and professional architecture that sets us up for success with GLTF import, custom effects, and long-term maintainability. What are your thoughts on this combined approach?


Create a new package called webgpu-renderer-gltf-loader
Install @gltf-transform/core as its only dependency.

Use it to traverse file and map to our renderer primitives.
Provide a hook so that consumers can detect extras and work with them:

// In the application code (the consumer)
import { GLTFSceneLoader } from '@digitalmeadow/webgpu-renderer-gltf-importer';
const renderer = new Renderer(canvas);
const sceneLoader = new GLTFSceneLoader(renderer);
const vehicleController = new VehicleController();
// Assign our custom node processing logic
sceneLoader.onProcessNode = (gltfNode, entity) => {
  const extras = gltfNode.getExtras();
  if (extras.isVehicleBody) {
    vehicleController.setBody(entity);
  }
  if (extras.isWheel) {
    const wheelRadius = extras.wheelRadius || 0.3;
    vehicleController.addWheel(entity, wheelRadius);
    
    // By returning false, we could tell the loader to *not*
    // create a visible mesh for this node if it's just a physics helper.
    return false; 
  }
  // Return true for all other nodes to get default processing.
  return true;
};
// Load the scene. Our hooks will be called automatically.
await sceneLoader.load(world, gltfData);
